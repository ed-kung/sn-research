{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b650868",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ekung/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import yaml \n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import ticker as mticker\n",
    "from matplotlib import colors as mcolors\n",
    "from matplotlib import patches as mpatches\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import subprocess\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, f1_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "import shap\n",
    "\n",
    "with open(\"../../config.yaml.local\", \"r\") as f:\n",
    "    LOCAL_CONFIG = yaml.safe_load(f)\n",
    "with open(\"../../config.yaml\", \"r\") as f:\n",
    "    CONFIG = yaml.safe_load(f)\n",
    "sys.path.append(\"../python\")\n",
    "\n",
    "import globals\n",
    "import data_tools as dt\n",
    "import utils\n",
    "import emb\n",
    "\n",
    "LOCAL_PATH = LOCAL_CONFIG[\"LOCAL_PATH\"]\n",
    "RAW_DATA_PATH = LOCAL_CONFIG[\"RAW_DATA_PATH\"]\n",
    "DATA_PATH = LOCAL_CONFIG[\"DATA_PATH\"]\n",
    "R_PATH = LOCAL_CONFIG[\"R_PATH\"]\n",
    "\n",
    "RUN_R_SCRIPTS = False\n",
    "OVERWRITE = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d348cb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ekung/projects/sn-research/src/notebooks/../python/data_tools.py:89: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  return x.dt.to_period('W-SAT').dt.start_time\n",
      "/Users/ekung/projects/sn-research/src/notebooks/../python/data_tools.py:89: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  return x.dt.to_period('W-SAT').dt.start_time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191334\n"
     ]
    }
   ],
   "source": [
    "df = dt.get_post_quality_analysis_data()\n",
    "\n",
    "df = df.loc[df['title'] != 'deleted by author'].reset_index(drop=True)\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ee7f425",
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = df['subName'].unique().tolist()\n",
    "sub_embeddings = {}\n",
    "for sub in subs:\n",
    "    embedding = np.array(emb.get_embedding_robust(sub))\n",
    "    embedding = embedding / np.linalg.norm(embedding)\n",
    "    sub_embeddings[sub] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56146983",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Query interrupted",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m text_embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m----> 5\u001b[0m     title_emb \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43memb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_embedding_robust\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtitle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      6\u001b[0m     title_emb \u001b[38;5;241m=\u001b[39m title_emb \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(title_emb)\n\u001b[1;32m      7\u001b[0m     title_embeddings\u001b[38;5;241m.\u001b[39mappend(title_emb)\n",
      "File \u001b[0;32m~/projects/sn-research/src/notebooks/../python/emb.py:136\u001b[0m, in \u001b[0;36mget_embedding_robust\u001b[0;34m(text, overwrite)\u001b[0m\n\u001b[1;32m    134\u001b[0m chunk_embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks:\n\u001b[0;32m--> 136\u001b[0m     emb \u001b[38;5;241m=\u001b[39m \u001b[43mget_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m     chunk_embeddings\u001b[38;5;241m.\u001b[39mappend(emb)\n\u001b[1;32m    138\u001b[0m chunk_lengths \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([token_length(chunk) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks])\n",
      "File \u001b[0;32m~/projects/sn-research/src/notebooks/../python/emb.py:121\u001b[0m, in \u001b[0;36mget_embedding\u001b[0;34m(text, overwrite)\u001b[0m\n\u001b[1;32m    119\u001b[0m text_hash \u001b[38;5;241m=\u001b[39m get_hash(text)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m overwrite:\n\u001b[0;32m--> 121\u001b[0m     cached_response \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_hash\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cached_response:\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(cached_response[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;66;03m# stored as tuple in duckdb\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/sn-research/src/notebooks/../python/emb.py:71\u001b[0m, in \u001b[0;36mcheck_cache\u001b[0;34m(text_hash)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck_cache\u001b[39m(text_hash):\n\u001b[0;32m---> 71\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43membedding_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSELECT embedding FROM embeddings WHERE text_hash = ?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_hash\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfetchone()\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Query interrupted"
     ]
    }
   ],
   "source": [
    "title_embeddings = []\n",
    "text_embeddings = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    title_emb = np.array(emb.get_embedding_robust(row['title']))\n",
    "    title_emb = title_emb / np.linalg.norm(title_emb)\n",
    "    title_embeddings.append(title_emb)\n",
    "    \n",
    "    text_emb = np.array(emb.get_embedding_robust(row['text']))\n",
    "    text_emb = text_emb / np.linalg.norm(text_emb)\n",
    "    text_embeddings.append(text_emb)\n",
    "\n",
    "title_embeddings = np.array(title_embeddings)\n",
    "text_embeddings = np.array(text_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bffad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for idx, row in df.iterrows():\n",
    "#    title = row['title']\n",
    "#    text = row['text']\n",
    "#    sub = row['subName']\n",
    "#    \n",
    "#    title_embedding = np.array(emb.get_embedding_robust(title))\n",
    "#    title_embedding = title_embedding / np.linalg.norm(title_embedding)\n",
    "#    \n",
    "#    text_embedding = np.array(emb.get_embedding_robust(text))\n",
    "#    text_embedding = text_embedding / np.linalg.norm(text_embedding)#\n",
    "#\n",
    "#    title_cos_dist = 1 - np.dot(title_embedding, sub_embeddings[sub])\n",
    "#    text_cos_dist = 1 - np.dot(text_embedding, sub_embeddings[sub])\n",
    "#\n",
    "#    df.at[idx, 'title_cos_dist'] = title_cos_dist\n",
    "#    df.at[idx, 'text_cos_dist'] = text_cos_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec6cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb.close_connections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbbdc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scree plot for title embeddings\n",
    "title_pca = PCA()\n",
    "title_pca.fit(title_embeddings)\n",
    "explained_variance = title_pca.explained_variance_ratio_[0:50]\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(range(1, len(explained_variance) + 1), explained_variance, marker='o')\n",
    "plt.title('Title Embeddings: PCA Scree Plot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.grid()\n",
    "#filename = os.path.join(LOCAL_PATH, 'figures', 'fig_scree_plot.pdf')\n",
    "#plt.savefig(filename, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c564a7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scree plot for text embeddings\n",
    "text_pca = PCA()\n",
    "text_pca.fit(text_embeddings)\n",
    "explained_variance = text_pca.explained_variance_ratio_[0:50]\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(range(1, len(explained_variance) + 1), explained_variance, marker='o')\n",
    "plt.title('Text Embeddings: PCA Scree Plot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.grid()\n",
    "#filename = os.path.join(LOCAL_PATH, 'figures', 'fig_scree_plot.pdf')\n",
    "#plt.savefig(filename, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b64497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TITLE_PCA_K = 20\n",
    "\n",
    "title_pca = PCA(n_components=TITLE_PCA_K)\n",
    "title_pca.fit(title_embeddings)\n",
    "title_pca_embeddings = title_pca.transform(title_embeddings)\n",
    "\n",
    "for k in range(TITLE_PCA_K):\n",
    "    df[f'title_emb_{k}'] = title_pca_embeddings[:, k]\n",
    "\n",
    "TEXT_PCA_K = 20\n",
    "\n",
    "text_pca = PCA(n_components=TEXT_PCA_K)\n",
    "text_pca.fit(text_embeddings)\n",
    "text_pca_embeddings = text_pca.transform(text_embeddings)\n",
    "\n",
    "for k in range(TEXT_PCA_K):\n",
    "    df[f'text_emb_{k}'] = text_pca_embeddings[:, k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37fa57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_emb_cols = [f'title_emb_{k}' for k in range(TITLE_PCA_K)]\n",
    "text_emb_cols = [f'text_emb_{k}' for k in range(TEXT_PCA_K)]\n",
    "feature_cols = ['num_words', 'num_img_or_links', 'is_link_post'] + title_emb_cols + text_emb_cols\n",
    "\n",
    "df['log_sats48'] = np.log1p(df['sats48'])\n",
    "\n",
    "X = df[feature_cols]\n",
    "Y = df['log_sats48']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=21)\n",
    "\n",
    "model = XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=21\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d035a74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca37775",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(Y, Y_pred))\n",
    "r2 = r2_score(Y, Y_pred)\n",
    "\n",
    "print(f\"XGB Model\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R2: {r2:.4f}\")\n",
    "print(f\"N: {len(Y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfa5f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLS model for comparison\n",
    "\n",
    "ols = LinearRegression(fit_intercept=True)\n",
    "ols.fit(X, Y)\n",
    "Y_pred_ols = ols.predict(X)\n",
    "rmse_ols = np.sqrt(mean_squared_error(Y, Y_pred_ols))\n",
    "r2_ols = r2_score(Y, Y_pred_ols)\n",
    "\n",
    "print(f\"OLS Model\")\n",
    "print(f\"RMSE: {rmse_ols:.4f}\")\n",
    "print(f\"R2: {r2_ols:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6d6197",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.Series(\n",
    "    model.feature_importances_, \n",
    "    index=model.feature_names_in_\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "fi = feature_importance.rename('importance').reset_index()\n",
    "fi['feature_group'] = fi['index']\n",
    "fi.loc[ fi['index'].isin(title_emb_cols), 'feature_group' ] = 'title_embeddings'\n",
    "fi.loc[ fi['index'].isin(text_emb_cols), 'feature_group' ] = 'text_embeddings'\n",
    "fi = fi.groupby('feature_group').agg(\n",
    "    importance = ('importance', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef25e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6f2571",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "shap.summary_plot(shap_values, X, max_display=7, show=False)\n",
    "plt.title(\"Top 7 Features for XGB Model Predicting Zaps in First 48 Hours\")\n",
    "plt.xlabel(\"SHAP value (impact on model prediction)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c511eaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Examples with high values of text_emb_5\")\n",
    "print(\"\")\n",
    "\n",
    "mydf = df.loc[ df['text_emb_5'] > np.quantile(df['text_emb_5'], 0.9) ].reset_index(drop=True)\n",
    "\n",
    "for idx, row in mydf.sample(3).iterrows():\n",
    "    print(f\"-------------\")\n",
    "    print(f\"Title: {row['title']}\")\n",
    "    print(f\"Territory: {row['subName']}\")\n",
    "    print(f\"URL: {row['url']}\")\n",
    "    print('')\n",
    "    print(row['text'])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acca1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['sats48']>0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c0caa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Examples with low values of text_emb_5\")\n",
    "print(\"\")\n",
    "\n",
    "mydf = df.loc[ df['text_emb_5'] < np.quantile(df['text_emb_5'], 0.1) ].reset_index(drop=True)\n",
    "\n",
    "for idx, row in mydf.sample(3).iterrows():\n",
    "    print(f\"-------------\")\n",
    "    print(f\"Title: {row['title']}\")\n",
    "    print(f\"Territory: {row['subName']}\")\n",
    "    print(f\"URL: {row['url']}\")\n",
    "    print('')\n",
    "    print(row['text'])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fb416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Examples with high values of text_emb_0\")\n",
    "print(\"\")\n",
    "\n",
    "mydf = df.loc[ df['text_emb_0'] > np.quantile(df['text_emb_0'], 0.9) ].reset_index(drop=True)\n",
    "\n",
    "for idx, row in mydf.sample(3).iterrows():\n",
    "    print(f\"-------------\")\n",
    "    print(f\"Title: {row['title']}\")\n",
    "    print(f\"Territory: {row['subName']}\")\n",
    "    print(f\"URL: {row['url']}\")\n",
    "    print('')\n",
    "    print(row['text'])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd45a0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Examples with low values of text_emb_0\")\n",
    "print(\"\")\n",
    "\n",
    "mydf = df.loc[ df['text_emb_0'] < np.quantile(df['text_emb_0'], 0.9) ].reset_index(drop=True)\n",
    "\n",
    "for idx, row in mydf.sample(3).iterrows():\n",
    "    print(f\"-------------\")\n",
    "    print(f\"Title: {row['title']}\")\n",
    "    print(f\"Territory: {row['subName']}\")\n",
    "    print(f\"URL: {row['url']}\")\n",
    "    print('')\n",
    "    print(row['text'])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54ae83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Examples with high values of text_emb_7\")\n",
    "print(\"\")\n",
    "\n",
    "mydf = df.loc[ df['text_emb_7'] > np.quantile(df['text_emb_7'], 0.9) ].reset_index(drop=True)\n",
    "\n",
    "for idx, row in mydf.sample(3).iterrows():\n",
    "    print(f\"-------------\")\n",
    "    print(f\"Title: {row['title']}\")\n",
    "    print(f\"Territory: {row['subName']}\")\n",
    "    print(f\"URL: {row['url']}\")\n",
    "    print('')\n",
    "    print(row['text'])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826462cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Examples with low values of text_emb_7\")\n",
    "print(\"\")\n",
    "\n",
    "mydf = df.loc[ df['text_emb_7'] < np.quantile(df['text_emb_7'], 0.1) ].reset_index(drop=True)\n",
    "\n",
    "for idx, row in mydf.sample(3).iterrows():\n",
    "    print(f\"-------------\")\n",
    "    print(f\"Title: {row['title']}\")\n",
    "    print(f\"Territory: {row['subName']}\")\n",
    "    print(f\"URL: {row['url']}\")\n",
    "    print('')\n",
    "    print(row['text'])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981a37fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Examples with high values of title_emb_1\")\n",
    "print(\"\")\n",
    "\n",
    "mydf = df.loc[ df['title_emb_1'] > np.quantile(df['title_emb_1'], 0.9) ].reset_index(drop=True)\n",
    "\n",
    "for idx, row in mydf.sample(3).iterrows():\n",
    "    print(f\"-------------\")\n",
    "    print(f\"Title: {row['title']}\")\n",
    "    print(f\"Territory: {row['subName']}\")\n",
    "    print(f\"URL: {row['url']}\")\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed19266",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Examples with low values of title_emb_1\")\n",
    "print(\"\")\n",
    "\n",
    "mydf = df.loc[ df['title_emb_1'] < np.quantile(df['title_emb_1'], 0.1) ].reset_index(drop=True)\n",
    "\n",
    "for idx, row in mydf.sample(3).iterrows():\n",
    "    print(f\"-------------\")\n",
    "    print(f\"Title: {row['title']}\")\n",
    "    print(f\"Territory: {row['subName']}\")\n",
    "    print(f\"URL: {row['url']}\")\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baef7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Diamonds in the rough\")\n",
    "print(\"\")\n",
    "\n",
    "df['log_sats48_pred'] = Y_pred\n",
    "df['residual'] = df['log_sats48'] - df['log_sats48_pred']\n",
    "\n",
    "mydf = df.sort_values(by='residual', ascending=True).head(5).reset_index(drop=True)\n",
    "\n",
    "print(\"| Item | Title | Territory |\")\n",
    "print(\"| ---- | ----- | --------- |\")\n",
    "for idx, row in mydf.iterrows():\n",
    "    print(\"| \", end='')\n",
    "    print(f\"https://stacker.news/items/{row['itemId']} | \", end='')\n",
    "    print(f\"{row['title']} | \", end='')\n",
    "    print(f\"{row['subName']} |\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb00f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output for regression in R\n",
    "df_out = df.drop(columns=text_emb_cols + title_emb_cols)\n",
    "out_filename = os.path.join(DATA_PATH, 'objective_quality_analysis.parquet')\n",
    "df_out.to_parquet(out_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
