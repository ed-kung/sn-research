{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b650868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml \n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "\n",
    "with open(\"../../config.yaml.local\", \"r\") as f:\n",
    "    LOCAL_CONFIG = yaml.safe_load(f)\n",
    "with open(\"../../config.yaml\", \"r\") as f:\n",
    "    CONFIG = yaml.safe_load(f)\n",
    "\n",
    "sys.path.append(\"../python\")\n",
    "\n",
    "import globals\n",
    "import data_tools as dt\n",
    "import emb\n",
    "import utils\n",
    "\n",
    "LOCAL_PATH = LOCAL_CONFIG[\"LOCAL_PATH\"]\n",
    "DATA_PATH = LOCAL_CONFIG[\"DATA_PATH\"]\n",
    "\n",
    "with open(os.path.join(LOCAL_PATH, 'metadata/models.json'), 'r') as f:\n",
    "    MODELS = json.load(f)\n",
    "model = MODELS[emb.EMBEDDING_MODEL]\n",
    "input_cost = model['input_cost']\n",
    "input_cost_batch = model['input_cost_batch']\n",
    "\n",
    "OVERWRITE = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80e8a144",
   "metadata": {},
   "outputs": [],
   "source": [
    "ESTIMATE_COSTS = False\n",
    "BATCH = False\n",
    "START_IDX = 0\n",
    "END_IDX = 99000\n",
    "BATCH_SIZE = 4000\n",
    "DATESTR = datetime.now().strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "706e619b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98098\n"
     ]
    }
   ],
   "source": [
    "posts = dt.get_posts()\n",
    "posts['text'] = posts['text'].fillna('')\n",
    "\n",
    "mask = (posts['invoiceActionState'] != 'FAILED') & \\\n",
    "    (~posts['bio']) & (~posts['freebie']) & (~posts['saloon']) & \\\n",
    "    (~posts['subName'].isin(['jobs', 'ama'])) & \\\n",
    "    (posts['title'] != 'deleted by author') & \\\n",
    "    (posts['text'].str.len() > 0)\n",
    "\n",
    "posts = posts.loc[mask].reset_index(drop=True)\n",
    "posts = posts.sort_values(by='itemId', ascending=True).reset_index(drop=True)\n",
    "print(len(posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bf85c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5,000 items ... elapsed time: 0.08 minutes\n",
      "Processed 10,000 items ... elapsed time: 0.16 minutes\n",
      "Processed 15,000 items ... elapsed time: 0.23 minutes\n",
      "Processed 20,000 items ... elapsed time: 0.30 minutes\n",
      "Processed 25,000 items ... elapsed time: 0.36 minutes\n",
      "Processed 30,000 items ... elapsed time: 0.43 minutes\n",
      "Processed 35,000 items ... elapsed time: 0.49 minutes\n",
      "Processed 40,000 items ... elapsed time: 0.55 minutes\n",
      "Processed 45,000 items ... elapsed time: 0.61 minutes\n",
      "Processed 50,000 items ... elapsed time: 0.67 minutes\n",
      "Processed 55,000 items ... elapsed time: 0.73 minutes\n",
      "Processed 60,000 items ... elapsed time: 0.80 minutes\n",
      "Processed 65,000 items ... elapsed time: 0.86 minutes\n",
      "Processed 70,000 items ... elapsed time: 0.92 minutes\n",
      "Processed 75,000 items ... elapsed time: 1.07 minutes\n",
      "Processed 80,000 items ... elapsed time: 1.14 minutes\n",
      "Processed 85,000 items ... elapsed time: 1.20 minutes\n",
      "Processed 90,000 items ... elapsed time: 1.27 minutes\n",
      "Processed 95,000 items ... elapsed time: 1.33 minutes\n",
      "Elapsed time: 1.37 minutes\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "texts_to_submit = []\n",
    "post_embeddings = []\n",
    "batch_num = 0\n",
    "total_requests = 0\n",
    "total_input_tokens = 0\n",
    "total_bytes = 0\n",
    "for idx, row in posts.iterrows():\n",
    "    if idx < START_IDX:\n",
    "        continue\n",
    "    if idx > END_IDX:\n",
    "        break\n",
    "    \n",
    "    title = row['title']\n",
    "    text = row['text']\n",
    "\n",
    "    if ESTIMATE_COSTS:\n",
    "        title_chunks = utils.split_to_max_length(title)\n",
    "        text_chunks = utils.split_to_max_length(text)\n",
    "        for chunk in title_chunks + text_chunks:\n",
    "            total_requests += 1\n",
    "            n_tokens = utils.token_length(chunk)\n",
    "            total_input_tokens += n_tokens\n",
    "            total_bytes += 64 + emb.EMBEDDING_DIMENSION*4  # 64B per hash, 4B per embedding dim\n",
    "    elif BATCH:\n",
    "        title_chunks = utils.split_to_max_length(title)\n",
    "        text_chunks = utils.split_to_max_length(text)\n",
    "        for chunk in title_chunks + text_chunks:\n",
    "            chunk_hash = utils.get_hash(chunk)\n",
    "            cached_response = emb.check_cache(chunk_hash)\n",
    "            if cached_response and not OVERWRITE:\n",
    "                continue\n",
    "            texts_to_submit.append(chunk)\n",
    "            if len(texts_to_submit) >= BATCH_SIZE:\n",
    "                batch_filename = f\"post_embeddings_batch_{DATESTR}_{START_IDX}_{END_IDX}_{batch_num}.jsonl\"\n",
    "                batch = emb.create_batch_job(texts_to_submit, batch_filename, overwrite=OVERWRITE)\n",
    "                batch_num += 1\n",
    "                texts_to_submit = []\n",
    "    else:\n",
    "        title_embedding = emb.get_embedding_robust(title, overwrite=OVERWRITE)\n",
    "        text_embedding = emb.get_embedding_robust(text, overwrite=OVERWRITE)\n",
    "        post_embeddings.append({\n",
    "            'itemId': row['itemId'],\n",
    "            'title_embedding': title_embedding,\n",
    "            'text_embedding': text_embedding\n",
    "        })\n",
    "    if ((idx+1)%5000)==0:\n",
    "        print(f\"Processed {idx+1:,} items ... elapsed time: {(time.time()-t0)/60:,.2f} minutes\")\n",
    "\n",
    "if (not ESTIMATE_COSTS) and (BATCH) and (len(texts_to_submit)>0):\n",
    "    batch_filename = f\"post_embeddings_batch_{DATESTR}_{START_IDX}_{END_IDX}_{batch_num}.jsonl\"\n",
    "    batch = emb.create_batch_job(texts_to_submit, batch_filename, overwrite=OVERWRITE)\n",
    "\n",
    "print(f\"Elapsed time: {(time.time()-t0)/60:,.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "441f4b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ESTIMATE_COSTS:\n",
    "    total_input_cost = (total_input_tokens / 1e6) * input_cost\n",
    "    total_input_cost_batch = (total_input_tokens / 1e6) * input_cost_batch\n",
    "    print(f\"Total requests: {total_requests:,}\")\n",
    "    print(f\"Input tokens: {total_input_tokens:,.0f}\")\n",
    "    print(f\"Total cost: ${total_input_cost:,.2f}\")\n",
    "    print(f\"Total cost (batch): ${total_input_cost_batch:,.2f}\")\n",
    "    print(f\"Total storage: {total_bytes / 1e9:,.2f} GB\")\n",
    "elif not BATCH:\n",
    "    post_embeddings_df = pd.DataFrame(post_embeddings)\n",
    "    outfilename = os.path.join(DATA_PATH, \"post_embeddings.pkl\")\n",
    "    post_embeddings_df.to_pickle(outfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1521283",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb.close_connections()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
