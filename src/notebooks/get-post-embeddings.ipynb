{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b650868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml \n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "\n",
    "with open(\"../../config.yaml.local\", \"r\") as f:\n",
    "    LOCAL_CONFIG = yaml.safe_load(f)\n",
    "with open(\"../../config.yaml\", \"r\") as f:\n",
    "    CONFIG = yaml.safe_load(f)\n",
    "\n",
    "sys.path.append(\"../python\")\n",
    "\n",
    "import globals\n",
    "import data_tools as dt\n",
    "import emb\n",
    "import utils\n",
    "\n",
    "LOCAL_PATH = LOCAL_CONFIG[\"LOCAL_PATH\"]\n",
    "DATA_PATH = LOCAL_CONFIG[\"DATA_PATH\"]\n",
    "\n",
    "with open(os.path.join(LOCAL_PATH, 'metadata/models.json'), 'r') as f:\n",
    "    MODELS = json.load(f)\n",
    "model = MODELS[emb.EMBEDDING_MODEL]\n",
    "input_cost = model['input_cost']\n",
    "input_cost_batch = model['input_cost_batch']\n",
    "\n",
    "OVERWRITE = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80e8a144",
   "metadata": {},
   "outputs": [],
   "source": [
    "ESTIMATE_COSTS = False\n",
    "BATCH = True\n",
    "START_IDX = 0\n",
    "END_IDX = 99000\n",
    "BATCH_SIZE = 4000\n",
    "DATESTR = datetime.now().strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "706e619b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191541\n"
     ]
    }
   ],
   "source": [
    "posts = dt.get_posts()\n",
    "posts['text'] = posts['text'].fillna('')\n",
    "\n",
    "mask = (posts['invoiceActionState'] != 'FAILED') & \\\n",
    "    (~posts['bio']) & (~posts['freebie']) & (~posts['saloon']) & \\\n",
    "    (~posts['subName'].isin(['jobs', 'ama'])) & \\\n",
    "    (posts['title'] != 'deleted by author') \n",
    "\n",
    "posts = posts.loc[mask].reset_index(drop=True)\n",
    "posts = posts.sort_values(by='itemId', ascending=True).reset_index(drop=True)\n",
    "print(len(posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bf85c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5,000 items ... elapsed time: 0.04 minutes\n",
      "Batch input file created: /Users/ekung/Dropbox/projects/sn-research/processed_data/batch/post_embeddings_batch_2025-11-14_0_99000_0.jsonl (3967 requests)\n",
      "Batch job created with ID: batch_69177e4e7bb48190b74b748edb2a50ca\n",
      "Processed 10,000 items ... elapsed time: 0.14 minutes\n",
      "Batch input file created: /Users/ekung/Dropbox/projects/sn-research/processed_data/batch/post_embeddings_batch_2025-11-14_0_99000_1.jsonl (3966 requests)\n",
      "Batch job created with ID: batch_69177e53af5c8190baeb518c1c164caa\n",
      "Processed 15,000 items ... elapsed time: 0.22 minutes\n",
      "Batch input file created: /Users/ekung/Dropbox/projects/sn-research/processed_data/batch/post_embeddings_batch_2025-11-14_0_99000_2.jsonl (3966 requests)\n",
      "Batch job created with ID: batch_69177e586f248190b93f810debe5f01d\n",
      "Processed 20,000 items ... elapsed time: 0.30 minutes\n",
      "Batch input file created: /Users/ekung/Dropbox/projects/sn-research/processed_data/batch/post_embeddings_batch_2025-11-14_0_99000_3.jsonl (3942 requests)\n",
      "Batch job created with ID: batch_69177e5ccf008190ba90d5b3cd2ab358\n",
      "Processed 25,000 items ... elapsed time: 0.38 minutes\n",
      "Batch input file created: /Users/ekung/Dropbox/projects/sn-research/processed_data/batch/post_embeddings_batch_2025-11-14_0_99000_4.jsonl (3958 requests)\n",
      "Batch job created with ID: batch_69177e620dc481908b3f1aa64ef1fe67\n",
      "Processed 30,000 items ... elapsed time: 0.46 minutes\n",
      "Batch input file created: /Users/ekung/Dropbox/projects/sn-research/processed_data/batch/post_embeddings_batch_2025-11-14_0_99000_5.jsonl (3948 requests)\n",
      "Batch job created with ID: batch_69177e667e2c8190890a6028295eb28c\n",
      "Processed 35,000 items ... elapsed time: 0.54 minutes\n",
      "Batch input file created: /Users/ekung/Dropbox/projects/sn-research/processed_data/batch/post_embeddings_batch_2025-11-14_0_99000_6.jsonl (3952 requests)\n",
      "Batch job created with ID: batch_69177e6bd2c081908c566bdf1964ce71\n",
      "Processed 40,000 items ... elapsed time: 0.62 minutes\n",
      "Batch input file created: /Users/ekung/Dropbox/projects/sn-research/processed_data/batch/post_embeddings_batch_2025-11-14_0_99000_7.jsonl (3945 requests)\n",
      "Batch job created with ID: batch_69177e70946081909897bb0ac28c817e\n",
      "Processed 45,000 items ... elapsed time: 0.70 minutes\n",
      "Batch input file created: /Users/ekung/Dropbox/projects/sn-research/processed_data/batch/post_embeddings_batch_2025-11-14_0_99000_8.jsonl (3923 requests)\n",
      "Batch job created with ID: batch_69177e7498e8819099aa928dd8fc996b\n",
      "Processed 50,000 items ... elapsed time: 0.77 minutes\n",
      "Batch input file created: /Users/ekung/Dropbox/projects/sn-research/processed_data/batch/post_embeddings_batch_2025-11-14_0_99000_9.jsonl (3927 requests)\n",
      "Batch job created with ID: batch_69177e793e5081908e41150ee6838519\n",
      "Processed 55,000 items ... elapsed time: 0.84 minutes\n",
      "Batch input file created: /Users/ekung/Dropbox/projects/sn-research/processed_data/batch/post_embeddings_batch_2025-11-14_0_99000_10.jsonl (3904 requests)\n",
      "Batch job created with ID: batch_69177e7d8614819082f938a45a943774\n",
      "Processed 60,000 items ... elapsed time: 0.90 minutes\n",
      "Batch input file created: /Users/ekung/Dropbox/projects/sn-research/processed_data/batch/post_embeddings_batch_2025-11-14_0_99000_11.jsonl (3843 requests)\n",
      "Batch job created with ID: batch_69177e8186348190a98b1817ba9734a4\n",
      "Processed 65,000 items ... elapsed time: 0.97 minutes\n",
      "Batch input file created: /Users/ekung/Dropbox/projects/sn-research/processed_data/batch/post_embeddings_batch_2025-11-14_0_99000_12.jsonl (3840 requests)\n",
      "Batch job created with ID: batch_69177e851c1c8190bea2a8b6ebfbb305\n",
      "Processed 70,000 items ... elapsed time: 1.02 minutes\n",
      "Processed 75,000 items ... elapsed time: 1.05 minutes\n",
      "Batch input file created: /Users/ekung/Dropbox/projects/sn-research/processed_data/batch/post_embeddings_batch_2025-11-14_0_99000_13.jsonl (3954 requests)\n",
      "Batch job created with ID: batch_69177e89b3f08190947350eb988d5712\n",
      "Processed 80,000 items ... elapsed time: 1.10 minutes\n",
      "Processed 85,000 items ... elapsed time: 1.13 minutes\n",
      "Batch input file created: /Users/ekung/Dropbox/projects/sn-research/processed_data/batch/post_embeddings_batch_2025-11-14_0_99000_14.jsonl (3946 requests)\n",
      "Batch job created with ID: batch_69177e8ed2208190bf3732e39274f567\n",
      "Processed 90,000 items ... elapsed time: 1.20 minutes\n",
      "Processed 95,000 items ... elapsed time: 1.23 minutes\n",
      "Batch input file created: /Users/ekung/Dropbox/projects/sn-research/processed_data/batch/post_embeddings_batch_2025-11-14_0_99000_15.jsonl (3961 requests)\n",
      "Batch job created with ID: batch_69177e95c2608190ba6e15b7f8e0606e\n",
      "Batch input file created: /Users/ekung/Dropbox/projects/sn-research/processed_data/batch/post_embeddings_batch_2025-11-14_0_99000_16.jsonl (372 requests)\n",
      "Batch job created with ID: batch_69177e97576481909f4b0137a1f4ce1b\n",
      "Elapsed time: 1.32 minutes\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "texts_to_submit = []\n",
    "post_embeddings = []\n",
    "batch_num = 0\n",
    "total_requests = 0\n",
    "total_input_tokens = 0\n",
    "total_bytes = 0\n",
    "for idx, row in posts.iterrows():\n",
    "    if idx < START_IDX:\n",
    "        continue\n",
    "    if idx > END_IDX:\n",
    "        break\n",
    "    \n",
    "    title = row['title']\n",
    "    text = row['text']\n",
    "\n",
    "    if ESTIMATE_COSTS:\n",
    "        title_chunks = utils.split_to_max_length(title)\n",
    "        text_chunks = utils.split_to_max_length(text)\n",
    "        for chunk in title_chunks + text_chunks:\n",
    "            total_requests += 1\n",
    "            n_tokens = utils.token_length(chunk)\n",
    "            total_input_tokens += n_tokens\n",
    "            total_bytes += 64 + emb.EMBEDDING_DIMENSION*4  # 64B per hash, 4B per embedding dim\n",
    "    elif BATCH:\n",
    "        title_chunks = utils.split_to_max_length(title)\n",
    "        text_chunks = utils.split_to_max_length(text)\n",
    "        for chunk in title_chunks + text_chunks:\n",
    "            chunk_hash = utils.get_hash(chunk)\n",
    "            cached_response = emb.check_cache(chunk_hash)\n",
    "            if cached_response and not OVERWRITE:\n",
    "                continue\n",
    "            texts_to_submit.append(chunk)\n",
    "            if len(texts_to_submit) >= BATCH_SIZE:\n",
    "                batch_filename = f\"post_embeddings_batch_{DATESTR}_{START_IDX}_{END_IDX}_{batch_num}.jsonl\"\n",
    "                batch = emb.create_batch_job(texts_to_submit, batch_filename, overwrite=OVERWRITE)\n",
    "                batch_num += 1\n",
    "                texts_to_submit = []\n",
    "    else:\n",
    "        title_embedding = emb.get_embedding_robust(title, overwrite=OVERWRITE)\n",
    "        text_embedding = emb.get_embedding_robust(text, overwrite=OVERWRITE)\n",
    "        post_embeddings.append({\n",
    "            'itemId': row['itemId'],\n",
    "            'title_embedding': title_embedding,\n",
    "            'text_embedding': text_embedding\n",
    "        })\n",
    "    if ((idx+1)%5000)==0:\n",
    "        print(f\"Processed {idx+1:,} items ... elapsed time: {(time.time()-t0)/60:,.2f} minutes\")\n",
    "\n",
    "if (not ESTIMATE_COSTS) and (BATCH) and (len(texts_to_submit)>0):\n",
    "    batch_filename = f\"post_embeddings_batch_{DATESTR}_{START_IDX}_{END_IDX}_{batch_num}.jsonl\"\n",
    "    batch = emb.create_batch_job(texts_to_submit, batch_filename, overwrite=OVERWRITE)\n",
    "\n",
    "print(f\"Elapsed time: {(time.time()-t0)/60:,.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "441f4b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ESTIMATE_COSTS:\n",
    "    total_input_cost = (total_input_tokens / 1e6) * input_cost\n",
    "    total_input_cost_batch = (total_input_tokens / 1e6) * input_cost_batch\n",
    "    print(f\"Total requests: {total_requests:,}\")\n",
    "    print(f\"Input tokens: {total_input_tokens:,.0f}\")\n",
    "    print(f\"Total cost: ${total_input_cost:,.2f}\")\n",
    "    print(f\"Total cost (batch): ${total_input_cost_batch:,.2f}\")\n",
    "    print(f\"Total storage: {total_bytes / 1e9:,.2f} GB\")\n",
    "elif not BATCH:\n",
    "    post_embeddings_df = pd.DataFrame(post_embeddings)\n",
    "    outfilename = os.path.join(DATA_PATH, \"post_embeddings.pkl\")\n",
    "    post_embeddings_df.to_pickle(outfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1521283",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb.close_connections()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
